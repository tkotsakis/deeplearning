{
 "cells": [
  {
   "source": [
    "# Neural Network to recognize Simpsons characters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "from os.path import isfile, join\n",
    "from os import listdir\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import shutil\n",
    "import random\n",
    "from distutils.dir_util import copy_tree\n",
    "import warnings\n",
    "from PIL import Image\n",
    "import os, sys\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will use the Simpsons dataset from kaggle https://www.kaggle.com/alexattia/the-simpsons-characters-dataset\n",
    "# The concept is that I downloaded the dataset into the folder that this notebook is executing and then from this original folder,I create with code train,validation and test directories with respective files inside it.I decided to train the entire dataset and validate it also and use about 1600 images available for test.\n",
    "#I will try to implement the notebook over all the simpsons characters, just to identify unknown areas in deep learning and learn more from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to list all files in directory and sub directories\n",
    "def list_files(dir):                                                                                                  \n",
    "    r = []                                                                                                            \n",
    "    subdirs = [x[0] for x in os.walk(dir)]                                                                            \n",
    "    for subdir in subdirs:                                                                                            \n",
    "        files = os.walk(subdir).__next__()[2]                                                                             \n",
    "        if (len(files) > 0):                                                                                          \n",
    "            for file in files:                                                                                        \n",
    "                r.append(os.path.join(subdir, file))                                                                         \n",
    "    return r    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to the directory where the original dataset was placed\n",
    "original_dataset_dir = './dataset/simpsons_dataset/'\n",
    "\n",
    "# Our working directory\n",
    "base_dir = './dataset/simpsons/'\n",
    "if (not os.path.exists(base_dir) ):\n",
    "    os.mkdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup train,validation and test directories\n",
    "train_dir = os.path.join(base_dir, 'train/')\n",
    "if (not os.path.exists(train_dir) ):\n",
    "    os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir, 'validation/')\n",
    "if (not os.path.exists(validation_dir) ):\n",
    "    os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir, 'test/')\n",
    "if (not os.path.exists(test_dir) ):\n",
    "    os.mkdir(test_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Directories for our training, validation and test splits.Copy images inside them\n",
    "\n",
    "# Get image names(path) to array\n",
    "simpsons_files = list_files(original_dataset_dir)\n",
    "\n",
    "#Shuffle array\n",
    "random.shuffle(simpsons_files)\n",
    "\n",
    "#Collection to store copied files, so as each folder to have different ones\n",
    "file_list = []\n",
    "\n",
    "#Copy entire dataset to train one\n",
    "copy_tree(original_dataset_dir,train_dir)\n",
    "\n",
    "#Copy entire dataset to validation one\n",
    "copy_tree(original_dataset_dir,validation_dir)\n",
    "\n",
    "#Get some files for test\n",
    "counter=0\n",
    "for fname in simpsons_files:\n",
    "    if fname in file_list:\n",
    "        continue\n",
    "    counter+=1\n",
    "    if (counter==7000):\n",
    "        break\n",
    "    dst = os.path.join(test_dir, os.path.basename(fname))\n",
    "    shutil.copyfile(fname, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('total validation simpsons classes:', len(os.listdir(train_dir)))\n",
    "print('total validation simpsons classes:', len(os.listdir(validation_dir)))\n",
    "print('total test simpsons images:', len(os.listdir(test_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = './dataset/simpsons_dataset'\n",
    "test_dataset = './dataset/simpsons_test_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get random image for testing\n",
    "img_width, img_height = 256, 384\n",
    "\n",
    "def getRandomImage(path, img_width, img_height):\n",
    "    \"\"\"function loads a random images from a random folder in our validation path \"\"\"\n",
    "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "    random_directory = np.random.randint(0,len(folders))\n",
    "    path_class = folders[random_directory]\n",
    "    file_path = path + path_class\n",
    "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "    random_file_index = np.random.randint(0,len(file_names))\n",
    "    image_name = file_names[random_file_index]\n",
    "    final_path = file_path + \"/\" + image_name\n",
    "    return image.load_img(final_path, target_size = (img_width, img_height)), final_path, path_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select some random images\n",
    "files = []\n",
    "\n",
    "for i in range(0, 3):\n",
    "    path = train_dir#'./dataset/simpsons_dataset/' \n",
    "    img, final_path, true_label = getRandomImage(path, img_width, img_height)\n",
    "    files.append(final_path)\n",
    "    img=mpimg.imread((files[i]))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image size for regenerator\n",
    "img_rows, img_cols = 150, 150\n",
    "batch_size = 20\n",
    "\n",
    "#Set up train and validation generators\n",
    "train_data_dir = train_dir#'./dataset/simpsons_dataset'\n",
    "validation_data_dir = validation_dir#'./dataset/simpsons_validation'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=30, width_shift_range=0.3, height_shift_range=0.3, horizontal_flip=True, fill_mode='nearest')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir, target_size=(img_rows, img_cols), batch_size=batch_size,class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_data_dir, target_size=(img_rows, img_cols), batch_size=batch_size, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get classes names and number of them\n",
    "from glob import glob\n",
    "classes = [i[15:-1].upper() for i in sorted(glob('./dataset//simpsons//train//*//'))]\n",
    "print(\"Classes: \",classes)\n",
    "num_classes = len(classes)\n",
    "print(\"Number of classes: \",num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare our model - New one working\n",
    "\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "# First CONV-ReLU Layer\n",
    "model.add(Conv2D(64, (3, 3), padding = 'same', activation='relu', input_shape = (img_rows, img_cols, 3)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Second CONV-ReLU Layer\n",
    "model.add(Conv2D(64, (3, 3), padding = \"same\", activation='relu', input_shape = (img_rows, img_cols, 3)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Max Pooling with Dropout \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# 3rd set of CONV-ReLU Layers\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 4th Set of CONV-ReLU Layers\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Max Pooling with Dropout \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# 5th Set of CONV-ReLU Layers\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 6th Set of CONV-ReLU Layers\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Max Pooling with Dropout \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# First set of FC or Dense Layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Second set of FC or Dense Layers\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(47, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create classes for storing our model and its layers,so as to be reusable enough\n",
    "class SimpsonsModel:\n",
    "    def __init__(self,train_dir,validation_dir,layers,rows,columns):\n",
    "        self.train_dir = train_dir\n",
    "        self.validation_dir = validation_dir\n",
    "        self.layers = list(layers)\n",
    "        self.rows = rows\n",
    "        self.columns = columns\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self,layer_type,layer_no,filters,kernel_size,padding,activation,input_shape,max_pooling,pool_size,batch_normalization,dropout,dropout_rate,units):\n",
    "        self.layer_type = layer_type\n",
    "        self.layer_no = layer_no\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        self.padding = padding\n",
    "        self.activation = activation\n",
    "        self.input_shape = input_shape\n",
    "        self.max_pooling = max_pooling\n",
    "        self.pool_size = pool_size\n",
    "        self.batch_normalization = batch_normalization\n",
    "        self.dropout = dropout\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.units = units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to prepare our model, can be decorated with future layers and custom implementation\n",
    "def PrepareModel(input_model):\n",
    "    model = Sequential()\n",
    "\n",
    "    for layer in input_model.layers:\n",
    "        print(str(layer.layer_no) + \" \" + layer.layer_type)\n",
    "        if (layer.layer_type == \"Conv2D\"):\n",
    "            if (layer.input_shape):\n",
    "                model.add(Conv2D(layer.filters, layer.kernel_size, padding = layer.padding, activation=layer.activation, input_shape = layer.input_shape))\n",
    "            else:\n",
    "                model.add(Conv2D(layer.filters, layer.kernel_size, padding = layer.padding, activation=layer.activation))\n",
    "        if (layer.layer_type == \"Flatten\"):\n",
    "            model.add(Flatten())\n",
    "            continue\n",
    "        if (layer.layer_type == \"Dense\"):\n",
    "            model.add(Dense(layer.units, activation=layer.activation))\n",
    "        if (layer.batch_normalization):\n",
    "            model.add(BatchNormalization())\n",
    "        if (layer.max_pooling):\n",
    "            model.add(MaxPooling2D(pool_size=layer.pool_size))\n",
    "        if (layer.dropout):\n",
    "            model.add(Dropout(layer.dropout_rate))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instatiate our simpsons model and pass layer parameters to it\n",
    "#Constructor needs layer_type,layer_no,filters,kernel_size,padding,activation,input_shape,max_pooling,pool_size,batch_normalization,dropout,dropout_rate,units\n",
    "\n",
    "layers = []\n",
    "\n",
    "layer1 = Layer(\"Conv2D\",1,64,(3, 3),'same','relu',(img_rows, img_cols, 3),False,(0,0),True,False,0,0)\n",
    "layer2 = Layer(\"Conv2D\",2,64,(3, 3),'same','relu',(img_rows, img_cols, 3),True,(2, 2),True,True,0.2,0)\n",
    "layer3 = Layer(\"Conv2D\",3,128,(3, 3),'same','relu',None,False,(0,0),True,False,0,0)\n",
    "layer4 = Layer(\"Conv2D\",4,128,(3, 3),'same','relu',None,True,(2, 2),True,True,0.2,0)\n",
    "layer5 = Layer(\"Conv2D\",5,256,(3, 3),'same','relu',None,False,(0,0),True,False,0,0)\n",
    "layer6 = Layer(\"Conv2D\",6,256,(3, 3),'same','relu',None,True,(2, 2),True,True,0.2,0)\n",
    "flatten = Layer(\"Flatten\",1,0,(0, 0),'','',None,True,(2, 2),False,False,0.0,0)\n",
    "dense1 = Layer(\"Dense\",1,0,(0, 0),'','relu',None,False,(0, 0),True,True,0.5,256)\n",
    "dense2 = Layer(\"Dense\",2,0,(0, 0),'','relu',None,False,(0, 0),True,True,0.5,256)\n",
    "dense3 = Layer(\"Dense\",3,0,(0, 0),'','sigmoid',None,False,(0, 0),False,False,0.0,num_classes)\n",
    "\n",
    "layers = [layer1,layer2,layer3,layer4,layer5,layer6,flatten,dense1,dense2,dense3]\n",
    "simpsonsModel = SimpsonsModel(train_dir,validation_dir,layers,img_rows,img_cols)\n",
    "model_new = PrepareModel(simpsonsModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check that are new model will be the same with the initiated one.Just verify that our function and class instatiation works as expected.\n",
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce LR , compile model and store callbacks so as to pass them to fit_generator\n",
    "#Set up train and validation generators\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.optimizers import SGD, Adam\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, verbose=1, min_delta=0.00001)\n",
    "callbacks = [reduce_lr]\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01), metrics=['accuracy'])\n",
    "\n",
    "# Rescale images by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir, target_size=(img_rows, img_cols), batch_size=batch_size,class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_data_dir, target_size=(img_rows, img_cols), batch_size=batch_size, class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train our model\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=50,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,\n",
    "      callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save('simpsons_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "#val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "#plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is module with image preprocessing utilities\n",
    "from keras.preprocessing import image\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "fnames = [os.path.join(train_data_dir, fname) for fname in os.listdir(train_data_dir)]\n",
    "files_1 = list_files(fnames[10])\n",
    "# We pick one image to \"augment\"\n",
    "img_path = files_1[5]#fnames[3]\n",
    "\n",
    "# Read the image and resize it\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "\n",
    "# Convert it to a Numpy array with shape (150, 150, 3)\n",
    "x = image.img_to_array(img)\n",
    "\n",
    "# Reshape it to (1, 150, 150, 3)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "# The .flow() command below generates batches of randomly transformed images.\n",
    "# It will loop indefinitely, so we need to `break` the loop at some point!\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1):\n",
    "    plt.figure(i)\n",
    "    imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
    "    i += 1\n",
    "    if i % 4 == 0:\n",
    "        break\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot training and validation accuracy and loss\n",
    "def plot_sets(history):\n",
    "    acc = history.history['accuracy']\n",
    "    #val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs, acc, 'rs')\n",
    "    #plt.plot(epochs, val_acc, 'g^')\n",
    "    plt.title('Training and validation accuracy')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'rs')\n",
    "    plt.plot(epochs, val_loss, 'g^')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.show()\n",
    "\n",
    "    plt.savefig('acc_vs_epochs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sets(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TASOS \n",
    "# We need to recreate our validation generator with shuffle = false\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_data_dir, target_size=(img_rows, img_cols),\n",
    "                                                              batch_size=batch_size, class_mode='categorical', shuffle=False)\n",
    "\n",
    "class_labels = validation_generator.class_indices\n",
    "class_labels = {v: k for k, v in class_labels.items()}\n",
    "classes = list(class_labels.values())\n",
    "\n",
    "nb_train_samples = 20933\n",
    "nb_validation_samples = 20933\n",
    "\n",
    "#Confution Matrix and Classification Report\n",
    "Y_pred = model.predict_generator(validation_generator, nb_validation_samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = list(class_labels.values())\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "cnf_matrix = confusion_matrix(validation_generator.classes, y_pred)\n",
    "\n",
    "plt.imshow(cnf_matrix, interpolation='nearest')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "_ = plt.xticks(tick_marks, classes, rotation=90)\n",
    "_ = plt.yticks(tick_marks, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def show_predictions(predictions,generator):\n",
    "    labels = [label_map[i] for i in range(len(label_map))]\n",
    "    y_true = [label_map[i] for i in generator.classes]\n",
    "    y_pred = [label_map[i] for i in predictions]\n",
    "    \n",
    "    print(len(generator.classes))\n",
    "    print(len(y_pred))\n",
    "    report = classification_report(y_true, y_pred, labels=labels)\n",
    "    print (str(report))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels)\n",
    "    \n",
    "    #print(cm)\n",
    "    fig = plt.figure(figsize = (10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(cm)\n",
    "    #plt.title('Confusion matrix of the classifier')\n",
    "    fig.colorbar(cax)\n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks, labels, rotation=90)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Truth')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(test_dir, \n",
    "                                                    target_size=(150, 150), \n",
    "                                                    batch_size=20, \n",
    "                                                    shuffle = False)\n",
    "\n",
    "checkpoint_filepath = \"./simpsons_model.h5\"\n",
    "checkpoint = ModelCheckpoint(checkpoint_filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history = model.fit_generator(train_generator, \n",
    "                                  steps_per_epoch=train_generator.n // train_generator.batch_size, \n",
    "                                  validation_data=validation_generator, \n",
    "                                  validation_steps=validation_generator.n // validation_generator.batch_size, \n",
    "                                  epochs=20, \n",
    "                                  workers=100, \n",
    "                                  shuffle=True,\n",
    "                                  callbacks=callbacks_list)\n",
    "\n",
    "# Plot training and dev: loss and accuracy\n",
    "plot_training_and_dev(history)\n",
    "\n",
    "# Predict test data\n",
    "predictions = model.predict_generator(test_generator, steps = test_generator.n // test_generator.batch_size)\n",
    "predictions = np.argmax(predictions, axis=-1) #multiple categories     \n",
    "show_predictions(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = model.predict_generator(validation_generator, steps = validation_generator.n // validation_generator.batch_size)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_data_dir, target_size=(img_rows, img_cols), batch_size=batch_size, class_mode='categorical')\n",
    "\n",
    "predictions = model.predict_generator(validation_generator, steps = 1047)\n",
    "predictions = np.argmax(predictions, axis=-1) #multiple categories     \n",
    "label_map = validation_generator.class_indices\n",
    "label_map = dict((v,k) for k,v in label_map.items()) #flip k,v\n",
    "num_classes = len(label_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_predictions(predictions,validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=5,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "source": [
    "# Testing Images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "class_labels = validation_generator.class_indices\n",
    "class_labels = {v: k for k, v in class_labels.items()}\n",
    "classes = list(class_labels.values())\n",
    "target_names = list(class_labels.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "class_labels = validation_generator.class_indices\n",
    "class_labels = {v: k for k, v in class_labels.items()}\n",
    "classes = list(class_labels.values())\n",
    "\n",
    "Y_pred = model.predict_generator(validation_generator, 100)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = list(class_labels.values())\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestImage(path,test_model):\n",
    "    img=mpimg.imread(path)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    img = image.load_img(path, target_size=(150, 150))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = x.astype('float32')/255\n",
    "    pred1 = np.argmax(test_model.predict(x))\n",
    "    print(\"Predicted character:{}.\".format(class_labels[pred1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model\n",
    "from keras.models import load_model\n",
    "model1 = load_model('./simpsons_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform test for random images and get predicted results\n",
    "\n",
    "path = test_dir\n",
    "for i in range(0,10):\n",
    "    random_filename = random.choice([\n",
    "        x for x in os.listdir(test_dir)\n",
    "        if os.path.isfile(os.path.join(path, x))\n",
    "    ])\n",
    "    random_filename = os.path.join(test_dir,random_filename)\n",
    "    print(\"Selected filename: \" + random_filename)\n",
    "\n",
    "    TestImage(random_filename,model1)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-approval",
   "metadata": {
    "papermill": {
     "duration": 0.029129,
     "end_time": "2021-04-07T16:23:54.300721",
     "exception": false,
     "start_time": "2021-04-07T16:23:54.271592",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Use pre-trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            # Note that since generators yield data indefinitely in a loop,\n",
    "            # we must `break` after every image has been seen once.\n",
    "            break\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_dir, 20933)\n",
    "validation_features, validation_labels = extract_features(validation_dir, 20933)\n",
    "test_features, test_labels = extract_features(test_dir, 1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.reshape(train_features, (20933, 4 * 4 * 512))\n",
    "validation_features = np.reshape(validation_features, (20933, 4 * 4 * 512))\n",
    "#test_features = np.reshape(test_features, (1600, 4 * 4 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "#model.add(layers.Dense(256, activation='relu', input_dim=4 * 4 * 512))\n",
    "#model.add(layers.Dropout(0.5))\n",
    "#model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.add(Dense(256, activation='relu',input_dim=32 * 32 * 512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256, activation='relu',input_dim=32 * 32 * 512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#model.compile(optimizer=optimizers.RMSprop(lr=2e-5),loss='categorical_crossentropy',metrics=['acc'])\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01), metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_features, train_labels,\n",
    "                    epochs=30,\n",
    "                    batch_size=20,\n",
    "                    validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretained model\n",
    "pretrained_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    pooling='avg'\n",
    ")\n",
    "\n",
    "pretrained_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-violence",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T16:23:54.369084Z",
     "iopub.status.busy": "2021-04-07T16:23:54.367699Z",
     "iopub.status.idle": "2021-04-07T16:52:59.047333Z",
     "shell.execute_reply": "2021-04-07T16:52:59.048667Z"
    },
    "papermill": {
     "duration": 1744.71895,
     "end_time": "2021-04-07T16:52:59.048884",
     "exception": false,
     "start_time": "2021-04-07T16:23:54.329934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = pretrained_model.input\n",
    "\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(47, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    validation_data=val_images,\n",
    "    epochs=50,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./simpsons2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-residence",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T16:53:04.288901Z",
     "iopub.status.busy": "2021-04-07T16:53:04.288176Z",
     "iopub.status.idle": "2021-04-07T16:53:04.461431Z",
     "shell.execute_reply": "2021-04-07T16:53:04.461978Z"
    },
    "papermill": {
     "duration": 2.790448,
     "end_time": "2021-04-07T16:53:04.462154",
     "exception": false,
     "start_time": "2021-04-07T16:53:01.671706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(hist.history)[['accuracy']].plot()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-ending",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T16:53:10.139605Z",
     "iopub.status.busy": "2021-04-07T16:53:10.138290Z",
     "iopub.status.idle": "2021-04-07T16:53:10.264849Z",
     "shell.execute_reply": "2021-04-07T16:53:10.264196Z"
    },
    "papermill": {
     "duration": 2.830378,
     "end_time": "2021-04-07T16:53:10.264973",
     "exception": false,
     "start_time": "2021-04-07T16:53:07.434595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(hist.history)[['loss','val_loss']].plot()\n",
    "plt.title(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-timer",
   "metadata": {
    "papermill": {
     "duration": 3.036263,
     "end_time": "2021-04-07T16:53:15.948532",
     "exception": false,
     "start_time": "2021-04-07T16:53:12.912269",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Visualize the result<a class=\"anchor\" id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-shoot",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T16:53:21.417535Z",
     "iopub.status.busy": "2021-04-07T16:53:21.416144Z",
     "iopub.status.idle": "2021-04-07T16:54:39.181891Z",
     "shell.execute_reply": "2021-04-07T16:54:39.182525Z"
    },
    "papermill": {
     "duration": 80.354816,
     "end_time": "2021-04-07T16:54:39.182727",
     "exception": false,
     "start_time": "2021-04-07T16:53:18.827911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict the label of the test_images\n",
    "pred = model.predict(test_images)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "# Map the label\n",
    "labels = (train_images.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "pred = [labels[k] for k in pred]\n",
    "\n",
    "# Display the result\n",
    "print(f'The first 5 predictions: {pred[:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-millennium",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T16:54:44.608569Z",
     "iopub.status.busy": "2021-04-07T16:54:44.607788Z",
     "iopub.status.idle": "2021-04-07T16:54:44.639106Z",
     "shell.execute_reply": "2021-04-07T16:54:44.640075Z"
    },
    "papermill": {
     "duration": 2.804046,
     "end_time": "2021-04-07T16:54:44.640259",
     "exception": false,
     "start_time": "2021-04-07T16:54:41.836213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_test = list(test_df.Label)\n",
    "acc = accuracy_score(y_test,pred)\n",
    "print(f'Accuracy on the test set: {acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-williams",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T16:54:50.123004Z",
     "iopub.status.busy": "2021-04-07T16:54:50.122019Z",
     "iopub.status.idle": "2021-04-07T16:54:50.295728Z",
     "shell.execute_reply": "2021-04-07T16:54:50.295057Z"
    },
    "papermill": {
     "duration": 2.86526,
     "end_time": "2021-04-07T16:54:50.295908",
     "exception": false,
     "start_time": "2021-04-07T16:54:47.430648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "class_report = classification_report(y_test, pred, zero_division=1)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-floating",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T16:54:56.231491Z",
     "iopub.status.busy": "2021-04-07T16:54:56.230785Z",
     "iopub.status.idle": "2021-04-07T16:54:57.545316Z",
     "shell.execute_reply": "2021-04-07T16:54:57.544878Z"
    },
    "papermill": {
     "duration": 4.60501,
     "end_time": "2021-04-07T16:54:57.545429",
     "exception": false,
     "start_time": "2021-04-07T16:54:52.940419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, pred, normalize='true')\n",
    "plt.figure(figsize = (20,15))\n",
    "sns.heatmap(cf_matrix, annot=False, xticklabels = sorted(set(y_test)), yticklabels = sorted(set(y_test)))\n",
    "plt.title('Normalized Confusion Matrix', fontsize = 23)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# Use of pre-trained model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import MobileNet\n",
    "\n",
    "conv_base = MobileNet(weights='imagenet',include_top=False,input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 1024))\n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            # Note that since generators yield data indefinitely in a loop,\n",
    "            # we must `break` after every image has been seen once.\n",
    "            break\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_dir, 20933)\n",
    "validation_features, validation_labels = extract_features(validation_dir, 20933)\n",
    "#test_features, test_labels = extract_features(test_dir, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.reshape(train_features, (20933, 4 * 4 * 1024))\n",
    "validation_features = np.reshape(validation_features, (20933, 4 * 4 * 1024))\n",
    "#test_features = np.reshape(test_features, (1000, 4 * 4 * 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "instant-moscow",
   "metadata": {
    "papermill": {
     "duration": 2.578342,
     "end_time": "2021-04-07T16:55:02.744051",
     "exception": false,
     "start_time": "2021-04-07T16:55:00.165709",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Examples of prediction<a class=\"anchor\" id=\"5\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Expose the real character values and the prediction ones\n",
    "counter=0\n",
    "\n",
    "for filename in test_df.Filepath:\n",
    "    counter+=1\n",
    "    print(\"Real Character: \" + test_df.Label.iloc[counter] + \" Predicted: \" + pred[counter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-delta",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T16:55:08.260136Z",
     "iopub.status.busy": "2021-04-07T16:55:08.259278Z",
     "iopub.status.idle": "2021-04-07T16:55:09.669038Z",
     "shell.execute_reply": "2021-04-07T16:55:09.669440Z"
    },
    "papermill": {
     "duration": 4.360115,
     "end_time": "2021-04-07T16:55:09.669595",
     "exception": false,
     "start_time": "2021-04-07T16:55:05.309480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display 15 picture of the dataset with their labels\n",
    "fig, axes = plt.subplots(nrows=4, ncols=5, figsize=(15, 12),subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(plt.imread(test_df.Filepath.iloc[i]))\n",
    "    ax.set_title(f\"True: {test_df.Label.iloc[i].split('_')[0]}\\nPredicted: {pred[i].split('_')[0]}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-happiness",
   "metadata": {
    "papermill": {
     "duration": 2.621858,
     "end_time": "2021-04-07T16:55:14.879771",
     "exception": false,
     "start_time": "2021-04-07T16:55:12.257913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing import image\n",
    "\n",
    "def post_validation(path):\n",
    "    img=mpimg.imread(path)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # prediction\n",
    "    img = image.load_img(path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = x.astype('float32')/255\n",
    "    pred1 = np.argmax(model.predict(x))\n",
    "    pred2 = np.argmax(model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_validation('./dataset/check/Abraham_Simpson.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_validation('./dataset/check/unnamed.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python386jvsc74a57bd016e3f6170213bc8b93f4af10cda404198c09c84502cee13f546aa00fc3fa8f5f",
   "display_name": "Python 3.8.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1949.623182,
   "end_time": "2021-04-07T16:55:21.262716",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-07T16:22:51.639534",
   "version": "2.3.2"
  },
  "metadata": {
   "interpreter": {
    "hash": "16e3f6170213bc8b93f4af10cda404198c09c84502cee13f546aa00fc3fa8f5f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}